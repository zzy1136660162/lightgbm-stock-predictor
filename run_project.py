#!/usr/bin/env python3
"""
é¡¹ç›®è¿è¡Œè„šæœ¬ - ç®€åŒ–ç‰ˆæµ‹è¯•æµç¨‹
"""
import sys
import os
import traceback

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def check_environment():
    """æ£€æŸ¥ç¯å¢ƒ"""
    print("=== ç¯å¢ƒæ£€æŸ¥ ===")
    
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    
    # æ£€æŸ¥GPU
    try:
        import subprocess
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print("âœ… NVIDIA GPU å¯ç”¨")
            if '3060' in result.stdout:
                print("ğŸ® RTX 3060/3060Ti å·²è¯†åˆ«")
        else:
            print("âš ï¸  NVIDIA GPU ä¸å¯ç”¨æˆ– nvidia-smi æœªå®‰è£…")
    except Exception as e:
        print(f"âš ï¸  GPUæ£€æŸ¥å¤±è´¥: {e}")
    
    return True

def test_data_module():
    """æµ‹è¯•æ•°æ®æ¨¡å—"""
    print("\n=== æµ‹è¯•æ•°æ®æ¨¡å— ===")
    
    try:
        from data_loader import load_stock_data
        print("âœ… data_loader æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•æ•°æ®åŠ è½½
        print("æ­£åœ¨åŠ è½½æ•°æ®...")
        data = load_stock_data()
        if data is not None and len(data) > 0:
            print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œå…± {len(data)} æ¡è®°å½•")
            print(f"   åˆ—å: {list(data.columns)}")
            print(f"   æ—¥æœŸèŒƒå›´: {data['date'].min()} åˆ° {data['date'].max()}")
            return True
        else:
            print("âš ï¸  æ•°æ®ä¸ºç©ºï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            return False
    except Exception as e:
        print(f"âŒ æ•°æ®æ¨¡å—æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def test_feature_module():
    """æµ‹è¯•ç‰¹å¾æ¨¡å—"""
    print("\n=== æµ‹è¯•ç‰¹å¾æ¨¡å— ===")
    
    try:
        from feature_engineering import feature_engineering_pipeline, calculate_technical_indicators
        print("âœ… feature_engineering æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        import pandas as pd
        import numpy as np
        
        dates = pd.date_range('2024-01-01', periods=100, freq='D')
        np.random.seed(42)
        
        test_data = pd.DataFrame({
            'date': dates,
            'open': 100 + np.cumsum(np.random.randn(100) * 0.5),
            'high': 101 + np.cumsum(np.random.randn(100) * 0.5),
            'low': 99 + np.cumsum(np.random.randn(100) * 0.5),
            'close': 100 + np.cumsum(np.random.randn(100) * 0.5),
            'volume': np.random.randint(1000000, 10000000, 100)
        })
        
        print("æ­£åœ¨å¤„ç†ç‰¹å¾å·¥ç¨‹...")
        processed_data = feature_engineering_pipeline(test_data)
        
        if processed_data is not None and len(processed_data) > 0:
            print(f"âœ… ç‰¹å¾å·¥ç¨‹æˆåŠŸ")
            print(f"   å¤„ç†å‰: {test_data.shape}")
            print(f"   å¤„ç†å: {processed_data.shape}")
            print(f"   ç‰¹å¾æ•°: {len(processed_data.columns)}")
            
            if 'target' in processed_data.columns:
                print(f"   ç›®æ ‡å˜é‡å·²åˆ›å»º")
            
            return True
        else:
            print("âŒ ç‰¹å¾å·¥ç¨‹å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ ç‰¹å¾æ¨¡å—æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def test_model_module():
    """æµ‹è¯•æ¨¡å‹æ¨¡å—"""
    print("\n=== æµ‹è¯•æ¨¡å‹æ¨¡å— ===")
    
    try:
        import lightgbm as lgb
        print("âœ… LightGBM å¯¼å…¥æˆåŠŸ")
        print(f"   LightGBM ç‰ˆæœ¬: {lgb.__version__}")
        
        # æ£€æŸ¥æ˜¯å¦æ”¯æŒGPU
        try:
            params = {
                'device': 'gpu',
                'gpu_platform_id': 0,
                'gpu_device_id': 0
            }
            print("âœ… LightGBM GPU æ”¯æŒå¯ç”¨")
        except:
            print("âš ï¸  LightGBM GPU æ”¯æŒä¸å¯ç”¨")
        
        return True
    except ImportError:
        print("âš ï¸  LightGBM æœªå®‰è£…ï¼Œå°è¯•ä½¿ç”¨ scikit-learn")
        try:
            from sklearn.ensemble import RandomForestRegressor
            print("âœ… scikit-learn å¯¼å…¥æˆåŠŸ")
            return True
        except ImportError:
            print("âŒ æœºå™¨å­¦ä¹ åº“ä¸å¯ç”¨")
            return False
    except Exception as e:
        print(f"âŒ æ¨¡å‹æ¨¡å—æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False

def run_simplified_workflow():
    """è¿è¡Œç®€åŒ–å·¥ä½œæµç¨‹"""
    print("\n=== è¿è¡Œç®€åŒ–å·¥ä½œæµç¨‹ ===")
    
    try:
        import pandas as pd
        import numpy as np
        
        # 1. åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        print("1. åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®...")
        dates = pd.date_range('2020-01-01', periods=500, freq='D')
        np.random.seed(42)
        
        # ç”Ÿæˆæ¨¡æ‹Ÿè‚¡ä»·æ•°æ®
        returns = np.random.randn(500) * 0.02
        prices = 100 * np.exp(np.cumsum(returns))
        
        data = pd.DataFrame({
            'date': dates,
            'open': prices * (1 + np.random.randn(500) * 0.01),
            'high': prices * (1 + np.abs(np.random.randn(500)) * 0.02),
            'low': prices * (1 - np.abs(np.random.randn(500)) * 0.02),
            'close': prices,
            'volume': np.random.randint(1000000, 10000000, 500)
        })
        
        print(f"   æ•°æ®å½¢çŠ¶: {data.shape}")
        
        # 2. ç‰¹å¾å·¥ç¨‹
        print("2. æ‰§è¡Œç‰¹å¾å·¥ç¨‹...")
        from feature_engineering import feature_engineering_pipeline
        processed_data = feature_engineering_pipeline(data)
        print(f"   å¤„ç†åæ•°æ®å½¢çŠ¶: {processed_data.shape}")
        
        # 3. å‡†å¤‡è®­ç»ƒæ•°æ®
        print("3. å‡†å¤‡è®­ç»ƒæ•°æ®...")
        feature_cols = [col for col in processed_data.columns 
                       if col not in ['date', 'open', 'high', 'low', 'close', 'volume', 'target']]
        X = processed_data[feature_cols].fillna(0)
        y = processed_data['target'].fillna(0)
        
        print(f"   ç‰¹å¾çŸ©é˜µ: {X.shape}")
        print(f"   ç›®æ ‡å˜é‡: {y.shape}")
        
        # 4. æ¨¡å‹è®­ç»ƒï¼ˆå¦‚æœå¯ç”¨ï¼‰
        print("4. æ¨¡å‹è®­ç»ƒ...")
        try:
            import lightgbm as lgb
            from sklearn.model_selection import train_test_split
            
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, shuffle=False
            )
            
            # æ£€æŸ¥GPUå¯ç”¨æ€§
            params = {
                'objective': 'regression',
                'metric': 'rmse',
                'boosting_type': 'gbdt',
                'num_leaves': 31,
                'learning_rate': 0.05,
                'feature_fraction': 0.9,
                'bagging_fraction': 0.8,
                'bagging_freq': 5,
                'verbose': 0
            }
            
            # å°è¯•ä½¿ç”¨GPU
            try:
                gpu_params = params.copy()
                gpu_params.update({
                    'device': 'gpu',
                    'gpu_platform_id': 0,
                    'gpu_device_id': 0
                })
                train_data = lgb.Dataset(X_train, label=y_train)
                model = lgb.train(gpu_params, train_data, num_boost_round=10)
                print("âœ… ä½¿ç”¨GPUè®­ç»ƒæˆåŠŸ")
            except:
                # å›é€€åˆ°CPU
                train_data = lgb.Dataset(X_train, label=y_train)
                model = lgb.train(params, train_data, num_boost_round=10)
                print("âœ… ä½¿ç”¨CPUè®­ç»ƒæˆåŠŸ")
            
            # é¢„æµ‹
            predictions = model.predict(X_test)
            print(f"   é¢„æµ‹å®Œæˆï¼Œå…± {len(predictions)} ä¸ªé¢„æµ‹å€¼")
            
            # ç‰¹å¾é‡è¦æ€§
            importance = model.feature_importance(importance_type='gain')
            feature_importance = pd.DataFrame({
                'feature': X.columns,
                'importance': importance
            }).sort_values('importance', ascending=False)
            
            print(f"   å‰5ä¸ªé‡è¦ç‰¹å¾:")
            for i in range(min(5, len(feature_importance))):
                row = feature_importance.iloc[i]
                print(f"     {row['feature']}: {row['importance']:.2f}")
            
        except ImportError:
            # ä½¿ç”¨scikit-learnä½œä¸ºå¤‡é€‰
            from sklearn.ensemble import RandomForestRegressor
            from sklearn.model_selection import train_test_split
            
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42
            )
            
            model = RandomForestRegressor(n_estimators=10, random_state=42, n_jobs=-1)
            model.fit(X_train, y_train)
            predictions = model.predict(X_test)
            print("âœ… ä½¿ç”¨RandomForestè®­ç»ƒæˆåŠŸ")
            print(f"   é¢„æµ‹å®Œæˆï¼Œå…± {len(predictions)} ä¸ªé¢„æµ‹å€¼")
        
        # 5. ä¿¡å·ç”Ÿæˆ
        print("5. ç”Ÿæˆäº¤æ˜“ä¿¡å·...")
        from signal_generator import generate_trading_signals
        
        signals = generate_trading_signals(predictions, threshold=0.001)
        print(f"   ç”Ÿæˆ {len(signals)} ä¸ªäº¤æ˜“ä¿¡å·")
        print(f"   ä¹°å…¥ä¿¡å·: {sum(1 for s in signals if s == 1)}")
        print(f"   å–å‡ºä¿¡å·: {sum(1 for s in signals if s == -1)}")
        print(f"   æŒæœ‰ä¿¡å·: {sum(1 for s in signals if s == 0)}")
        
        # 6. å›æµ‹
        print("6. è¿è¡Œå›æµ‹...")
        from backtester import Backtester
        
        # åˆ›å»ºå›æµ‹æ•°æ®
        backtest_data = processed_data.tail(len(predictions)).copy()
        backtest_data = backtest_data.reset_index(drop=True)
        
        # æ·»åŠ ä¿¡å·
        backtest_data.loc[:, 'signal'] = signals[:len(backtest_data)]
        
        backtester = Backtester(initial_cash=100000, transaction_fee=0.001, slippage=0.001)
        results = backtester.run_backtest(backtest_data)
        
        if results:
            print("âœ… å›æµ‹å®Œæˆ")
            print(f"   åˆå§‹èµ„é‡‘: {results['initial_cash']:,.2f}")
            print(f"   æœ€ç»ˆä»·å€¼: {results['final_value']:,.2f}")
            print(f"   æ€»æ”¶ç›Šç‡: {results['total_return']:.2%}")
            print(f"   å¹´åŒ–æ”¶ç›Š: {results['annual_return']:.2%}")
            print(f"   å¤æ™®æ¯”ç‡: {results['sharpe_ratio']:.2f}")
            print(f"   æœ€å¤§å›æ’¤: {results['max_drawdown']:.2%}")
        else:
            print("âš ï¸  å›æµ‹æœªè¿”å›ç»“æœ")
        
        print("\nâœ… ç®€åŒ–å·¥ä½œæµç¨‹å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ å·¥ä½œæµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("         LightGBMè‚¡ç¥¨é¢„æµ‹é¡¹ç›®æµ‹è¯•")
    print("=" * 60)
    
    # ç¯å¢ƒæ£€æŸ¥
    check_environment()
    
    # æ¨¡å—æµ‹è¯•
    data_ok = test_data_module()
    features_ok = test_feature_module()
    model_ok = test_model_module()
    
    # è¿è¡Œå·¥ä½œæµç¨‹
    workflow_ok = False
    if data_ok and features_ok and model_ok:
        workflow_ok = run_simplified_workflow()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("                    æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    print(f"âœ… æ•°æ®æ¨¡å—: {'é€šè¿‡' if data_ok else 'å¤±è´¥'}")
    print(f"âœ… ç‰¹å¾æ¨¡å—: {'é€šè¿‡' if features_ok else 'å¤±è´¥'}")
    print(f"âœ… æ¨¡å‹æ¨¡å—: {'é€šè¿‡' if model_ok else 'å¤±è´¥'}")
    print(f"âœ… å·¥ä½œæµç¨‹: {'é€šè¿‡' if workflow_ok else 'å¤±è´¥'}")
    
    if all([data_ok, features_ok, model_ok, workflow_ok]):
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é¡¹ç›®å¯ä»¥æ­£å¸¸è¿è¡Œã€‚")
        print("\nğŸ“Š ä¸‹ä¸€æ­¥å»ºè®®ï¼š")
        print("   1. å®‰è£…å®Œæ•´ä¾èµ–: pip install -r requirements.txt")
        print("   2. è¿è¡Œå®Œæ•´é¡¹ç›®: python main.py")
        print("   3. è°ƒæ•´å‚æ•°: ç¼–è¾‘ config.yaml æ–‡ä»¶")
        print("   4. æŸ¥çœ‹ç»“æœ: æ£€æŸ¥ output/ ç›®å½•")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¾èµ–é¡¹å’Œä»£ç ã€‚")
        if not model_ok:
            print("   å»ºè®®å®‰è£… LightGBM: pip install lightgbm")
    
    print("=" * 60)

if __name__ == "__main__":
    main()